{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WaA74L0HeTUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ff5e20-3205-42a9-a2fa-d42c491bccb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Documents: [['love', 'cat', 'cat'], ['love', 'dog'], ['love', 'dog', 'cat']]\n",
            "IDF for love: 0.000\n",
            "IDF for cat: 0.176\n",
            "IDF for dog: 0.176\n",
            "\n",
            "TF-IDF Document-Term Matrix:\n",
            "               love      cat       dog       \n",
            "d1             0.00      0.12      0.00      \n",
            "d2             0.00      0.00      0.09      \n",
            "d3             0.00      0.06      0.06      \n"
          ]
        }
      ],
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# AUTHOR: Mahakbhai Patel\n",
        "# FILENAME: indexing.py\n",
        "# SPECIFICATION: This program reads a file collection.csv, processes the text by removing stopwords,\n",
        "#                performs stemming, identifies index terms, and calculates the TF-IDF document-term matrix.\n",
        "# FOR: CS 5180 - Assignment #1\n",
        "# TIME SPENT: how long it took you to complete the assignment\n",
        "#-----------------------------------------------------------*/\n",
        "\n",
        "# Importing necessary libraries\n",
        "import csv\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Reading the documents from a CSV file\n",
        "documents = []\n",
        "with open('collection.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)  # Skip the header row\n",
        "    for row in reader:\n",
        "        documents.append(row[0])  # Document text in the first column\n",
        "\n",
        "# Step 2: Conducting stopword removal for pronouns/conjunctions. Using a set to define stopwords.\n",
        "stopWords = {\"i\", \"she\", \"he\", \"they\", \"her\", \"their\", \"and\", \"is\", \"the\", \"a\", \"an\"}\n",
        "\n",
        "def remove_stopwords(doc):\n",
        "    words = doc.lower().split()\n",
        "    return [word for word in words if word not in stopWords]\n",
        "\n",
        "# Step 3: Conducting simple stemming. Using a dictionary to map word variations to their stem.\n",
        "stemming = {\n",
        "    \"cats\": \"cat\",\n",
        "    \"dogs\": \"dog\",\n",
        "    \"loves\": \"love\",\n",
        "    \"love\": \"love\"\n",
        "}\n",
        "\n",
        "def apply_stemming(words):\n",
        "    return [stemming.get(word, word) for word in words]\n",
        "\n",
        "# Step 4: Preprocessing the documents (removing stopwords and applying stemming)\n",
        "processed_documents = []\n",
        "for doc in documents:\n",
        "    words = remove_stopwords(doc)\n",
        "    stemmed_words = apply_stemming(words)\n",
        "    processed_documents.append(stemmed_words)\n",
        "\n",
        "print(\"Processed Documents:\", processed_documents)\n",
        "\n",
        "# Step 5: Identifying the index terms (vocabulary)\n",
        "terms = ['love', 'cat', 'dog']  # Fixed order of terms for TF-IDF calculation\n",
        "\n",
        "# Step 6: Calculating TF (Term Frequency), IDF (Inverse Document Frequency), and TF-IDF\n",
        "N = len(processed_documents)\n",
        "\n",
        "# Function to calculate term frequency (TF)\n",
        "def compute_tf(term, doc):\n",
        "    return doc.count(term) / len(doc)  # Normalized term frequency\n",
        "\n",
        "# Function to calculate inverse document frequency (IDF)\n",
        "def compute_idf(term):\n",
        "    doc_count = sum(1 for doc in processed_documents if term in doc)\n",
        "    return math.log10(N / doc_count) if doc_count > 0 else 0\n",
        "\n",
        "# Print IDF values for debugging\n",
        "for term in terms:\n",
        "    idf = compute_idf(term)\n",
        "    print(f\"IDF for {term}: {idf:.3f}\")\n",
        "\n",
        "# Step 7: Constructing the TF-IDF document-term matrix\n",
        "docTermMatrix = []\n",
        "for doc in processed_documents:\n",
        "    tfidf_values = []\n",
        "    for term in terms:\n",
        "        tf = compute_tf(term, doc)\n",
        "        idf = compute_idf(term)\n",
        "        tfidf = tf * idf\n",
        "        tfidf_values.append(tfidf)\n",
        "    docTermMatrix.append(tfidf_values)\n",
        "\n",
        "# Step 8: Printing the TF-IDF document-term matrix\n",
        "print(\"\\nTF-IDF Document-Term Matrix:\")\n",
        "print(f\"{'':<15}{'love':<10}{'cat':<10}{'dog':<10}\")  # Term headers\n",
        "for idx, doc_label in enumerate(['d1', 'd2', 'd3']):\n",
        "    row = [f\"{doc_label:<15}\"] + \\\n",
        "        [f\"{value:.2f}\".ljust(10) for value in docTermMatrix[idx]]\n",
        "    print(\"\".join(row))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "gbCBrxxcel03"
      }
    }
  ]
}